{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import mat73\n",
    "from os.path import basename, dirname, join\n",
    "\n",
    "# IPython-Specific\n",
    "from IPython.display import display\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "# Mesostat includes\n",
    "from mesostat.utils.system import strlst2date\n",
    "from mesostat.utils.arrays import bin_data_by_keys, slice_sorted\n",
    "from mesostat.utils.pandas_helper import get_rows_colval, get_rows_colvals\n",
    "from mesostat.utils.matlab_helper import loadmat\n",
    "from mesostat.utils.system import getfiles_walk\n",
    "\n",
    "# Local libraries\n",
    "from lib.sych.mouse_performance import mouse_performance_allsessions\n",
    "from lib.sych.data_read import read_neuro_perf, read_paw, read_lick, read_whisk, readTE_H5, parse_TE_folder, session_name_to_mousename\n",
    "from lib.sych.behaviour_preprocess import resample_lick, resample_paw, resample_whisk\n",
    "\n",
    "\n",
    "class DataFCDatabase :\n",
    "    def __init__(self, param):\n",
    "\n",
    "        # Find and parse Data filenames\n",
    "        self.mice = set()\n",
    "        self.metaDataFrames = {}\n",
    "\n",
    "        ##################################\n",
    "        # Define resampling frequency\n",
    "        ##################################\n",
    "        self.targetRange = [0, 8]  # Seconds goal\n",
    "        self.targetFreq = 20  # Hz\n",
    "        self.targetNTimes = int((self.targetRange[1] - self.targetRange[0]) * self.targetFreq) + 1\n",
    "        self.targetTimes = np.linspace(self.targetRange[0], self.targetRange[1], self.targetNTimes)\n",
    "        print(\"Target trial within\", self.targetRange, \"sec. Total target timesteps\", self.targetNTimes)\n",
    "\n",
    "        ##################################\n",
    "        # Find and parse data files\n",
    "        ##################################\n",
    "        if \"root_path_data\" in param.keys():\n",
    "            print(\"Searching for channel labels\")\n",
    "            self._find_parse_channel_labels(param[\"root_path_data\"])\n",
    "            print(\"Searching for data files\")\n",
    "            self._find_parse_neuro_files(param[\"root_path_data\"])\n",
    "        else:\n",
    "            print(\"No data path provided, skipping\")\n",
    "\n",
    "        ##################################\n",
    "        # Compute summary\n",
    "        ##################################\n",
    "        sumByMouse = lambda dataset: [dataset[dataset['mousename'] == mousename].shape[0] for mousename in self.mice]\n",
    "\n",
    "        self.summary = pd.DataFrame({\n",
    "            key : sumByMouse(dataFrame) for key, dataFrame in self.metaDataFrames.items()\n",
    "        }, index=self.mice)\n",
    "\n",
    "    # Channel labels are brain regions associated to each channel index\n",
    "    # The channel labels need not be consistent across mice, or even within one mouse\n",
    "    def _find_parse_channel_labels(self, path):\n",
    "        labelPaths = getfiles_walk(path, ['channel_labels.mat'])\n",
    "        channelDict = {basename(path) : join(path, name) for path, name in labelPaths}\n",
    "        #self.metaDataFrames['channel_labels'] = pd.DataFrame(channelDict, index=['mousename', 'path'])\n",
    "        self.channelLabelsDict = {mousename : loadmat(path)['channel_labels'] for mousename, path in channelDict.items()}\n",
    "\n",
    "        self.mice.update(set(channelDict.keys()))\n",
    "\n",
    "    def _find_parse_neuro_files(self, path):\n",
    "        dataPaths = getfiles_walk(path, [\"data.mat\"])\n",
    "        neuroData = [[\n",
    "            basename(path),\n",
    "            path,\n",
    "            basename(dirname(path)),\n",
    "            strlst2date(basename(path).split(\"_\")[2:5])\n",
    "          ] for path, name in dataPaths\n",
    "        ]\n",
    "        neuroDict = {k: v for k, v in zip(['mousekey', 'path', 'mousename', 'date'], np.array(neuroData).T)}\n",
    "        self.metaDataFrames['neuro'] = pd.DataFrame(neuroDict)\n",
    "        self.mice.update(set(self.metaDataFrames['neuro']['mousename']))\n",
    "\n",
    "    def _find_parse_paw_files(self, path):\n",
    "        paw_paths = getfiles_walk(path, [\"deltaI_paw.mat\"])\n",
    "        paw_data = [[\n",
    "            basename(path),\n",
    "            path,\n",
    "            basename(dirname(path)),\n",
    "            strlst2date(basename(path).split(\"_\")[2:5])\n",
    "          ] for path, name in paw_paths\n",
    "        ]\n",
    "        paw_dict = {k: v for k, v in zip(['mousekey', 'path', 'mousename', 'date'], np.array(paw_data).T)}\n",
    "        self.metaDataFrames['paw'] = pd.DataFrame(paw_dict)\n",
    "        self.mice.update(set(self.metaDataFrames['paw']['mousename']))\n",
    "\n",
    "    def _find_parse_lick_files(self, path):\n",
    "        lick_paths = getfiles_walk(path, [\"lick_traces.mat\"])\n",
    "        lick_data = [[\n",
    "            basename(path),\n",
    "            path,\n",
    "            basename(dirname(path)),\n",
    "            strlst2date(basename(path).split(\"_\")[2:5])\n",
    "          ] for path, name in lick_paths\n",
    "        ]\n",
    "        lick_dict = {k: v for k, v in zip(['mousekey', 'path', 'mousename', 'date'], np.array(lick_data).T)}\n",
    "        self.metaDataFrames['lick'] = pd.DataFrame(lick_dict)\n",
    "        self.mice.update(set(self.metaDataFrames['lick']['mousename']))\n",
    "\n",
    "    def _find_parse_whisk_files(self, path):\n",
    "        whisk_paths = getfiles_walk(path, [\"whiskAngle.mat\"])\n",
    "        whisk_data = [[\n",
    "            basename(path),\n",
    "            path,\n",
    "            basename(dirname(path)),\n",
    "            strlst2date(basename(path).split(\"_\")[2:5])\n",
    "          ] for path, name in whisk_paths\n",
    "        ]\n",
    "        whisk_dict = {k: v for k, v in zip(['mousekey', 'path', 'mousename', 'date'], np.array(whisk_data).T)}\n",
    "        self.metaDataFrames['whisk'] = pd.DataFrame(whisk_dict)\n",
    "        self.mice.update(set(self.metaDataFrames['whisk']['mousename']))\n",
    "\n",
    "    def read_te_files(self):\n",
    "        if \"TE\" in self.metaDataFrames.keys():\n",
    "            self.dataTEtimes = []  # Timesteps for neuronal data\n",
    "            self.dataTEFC = []     # (te, lag, p) of FC estimate\n",
    "\n",
    "            progBar = IntProgress(min=0, max=len(self.metaDataFrames[\"TE\"][\"path\"]), description='Reading TE files')\n",
    "            display(progBar)  # display the bar\n",
    "            for fpath in self.metaDataFrames[\"TE\"][\"path\"]:\n",
    "                times, data = readTE_H5(fpath, self.summaryTE)\n",
    "                self.dataTEtimes += [times]\n",
    "                self.dataTEFC += [data]\n",
    "                progBar.value += 1\n",
    "        else:\n",
    "            print(\"No TE files loaded, skipping reading part\")\n",
    "\n",
    "    def read_neuro_files(self):\n",
    "        if 'neuro' in self.metaDataFrames.keys():\n",
    "            nNeuroFiles = self.metaDataFrames['neuro'].shape[0]\n",
    "\n",
    "            self.dataNeuronal = []\n",
    "            self.dataTrials = []\n",
    "            self.dataPerformance = []\n",
    "            badPerfIdxs = []\n",
    "\n",
    "            progBar = IntProgress(min=0, max=nNeuroFiles, description='Read Neuro Data:')\n",
    "            display(progBar)  # display the bar\n",
    "            for idx, datapath in enumerate(self.metaDataFrames['neuro']['path']):\n",
    "                data, behaviour, performance = read_neuro_perf(datapath, verbose=False)\n",
    "                if (performance >= 0) and (performance <= 1):\n",
    "                    self.dataNeuronal += [data]\n",
    "                    self.dataTrials += [behaviour]\n",
    "                    self.dataPerformance += [performance]\n",
    "                else:\n",
    "                    badPerfIdxs += [idx]\n",
    "                progBar.value += 1\n",
    "            self.dataPerformance = np.array(self.dataPerformance)\n",
    "\n",
    "            # Drop all mice for which performance exceeds 1\n",
    "            nBadPerfIdxs = len(badPerfIdxs)\n",
    "            if nBadPerfIdxs > 0:\n",
    "                print(\"Bad performance in\", nBadPerfIdxs, \"sessions, fixing\")\n",
    "                nRowsBefore = self.metaDataFrames['neuro'].shape[0]\n",
    "                self.metaDataFrames['neuro'] = self.metaDataFrames['neuro'].drop(badPerfIdxs).reset_index(drop=True)\n",
    "                nRowsAfter = self.metaDataFrames['neuro'].shape[0]\n",
    "                if nRowsBefore - nRowsAfter != nBadPerfIdxs:\n",
    "                    raise ValueError(\"Bad stuff\", nRowsBefore, nRowsAfter, nBadPerfIdxs)\n",
    "\n",
    "            # Fix mousekeys to remove trailing underscore\n",
    "            for idx, row in self.metaDataFrames['neuro'].iterrows():\n",
    "                if row['mousekey'][-1] == '_':\n",
    "                    self.metaDataFrames['neuro'].at[idx, 'mousekey'] = row['mousekey'][:-1]\n",
    "        else:\n",
    "            print(\"No Neuro files loaded, skipping reading part\")\n",
    "\n",
    "    def read_resample_paw_files(self):\n",
    "        if 'paw' in self.metaDataFrames.keys():\n",
    "            nPawFiles = self.metaDataFrames['paw'].shape[0]\n",
    "            dataPawResampled = []\n",
    "            progBar = IntProgress(min=0, max=nPawFiles, description='Read paw data:')\n",
    "            display(progBar) # display the bar\n",
    "            for pawpath in self.metaDataFrames['paw']['path']:\n",
    "                dataPaw = read_paw(pawpath, verbose=False)\n",
    "                dataPawResampled += [resample_paw(dataPaw, self.targetTimes, self.targetFreq)]\n",
    "                progBar.value += 1\n",
    "        else:\n",
    "            print(\"No paw files loaded, skipping reading part\")\n",
    "\n",
    "    def read_resample_lick_files(self):\n",
    "        if 'lick' in self.metaDataFrames.keys():\n",
    "            nLickFiles = self.metaDataFrames['lick'].shape[0]\n",
    "            self.dataLickResampled = []\n",
    "            progBar = IntProgress(min=0, max=nLickFiles, description='Read lick data:')\n",
    "            display(progBar) # display the bar\n",
    "\n",
    "            for index, row in self.metaDataFrames['lick'].iterrows():\n",
    "                # Find behaviour associated with this lick\n",
    "                dataIdxs = get_rows_colval(self.metaDataFrames['lick'], 'mousekey', row['mousekey']).index\n",
    "                if dataIdxs.shape[0] == 0:\n",
    "                    self.dataLickResampled += [None]\n",
    "                else:\n",
    "                    dataIdx = dataIdxs[0]\n",
    "                    neuro = self.dataNeuronal[dataIdx]\n",
    "                    behaviour = self.dataTrials[dataIdx]\n",
    "                    dataLick = read_lick(row['path'], verbose=False)\n",
    "                    self.dataLickResampled += [resample_lick(dataLick, neuro, behaviour, self.targetTimes, self.targetFreq)]\n",
    "                progBar.value += 1\n",
    "        else:\n",
    "            print(\"No lick files loaded, skipping reading part\")\n",
    "\n",
    "    def read_resample_whisk_files(self):\n",
    "        if 'whisk' in self.metaDataFrames.keys():\n",
    "            nWhiskFiles = self.metaDataFrames['whisk'].shape[0]\n",
    "            progBar = IntProgress(min=0, max=nWhiskFiles, description='Read whisk data:')\n",
    "            display(progBar) # display the bar\n",
    "            self.dataWhiskResampled = []\n",
    "            for whiskpath in self.metaDataFrames['whisk']['path']:\n",
    "                dataWhisk = read_whisk(whiskpath, verbose=False)\n",
    "                self.dataWhiskResampled += [resample_whisk(dataWhisk, self.targetTimes)]\n",
    "                progBar.value += 1\n",
    "        else:\n",
    "            print(\"No whisk files loaded, skipping reading part\")\n",
    "\n",
    "    def read_pooled_behaviour(self, path):\n",
    "        # Read data\n",
    "        data = mat73.loadmat(path)['behavior']\n",
    "\n",
    "        # Create metadataframe for behaviour\n",
    "        pooledFrame = pd.DataFrame(columns=['mousename', 'mousekey'])\n",
    "        self.dataBehaviourPooled = []\n",
    "        self.dataBehaviourPooledKeys = set()\n",
    "\n",
    "        for dataMouse in data:\n",
    "            print(len(dataMouse))\n",
    "            for dataSession in dataMouse:\n",
    "                if 'session_names' in dataSession.keys():\n",
    "                    mousekey = dataSession['session_names']\n",
    "                    mousename = session_name_to_mousename(mousekey)\n",
    "\n",
    "                    row = pd.DataFrame([[mousekey, mousename]], columns=['mousename', 'mousekey'])\n",
    "                    pooledFrame = pooledFrame.append(row, ignore_index=True)\n",
    "\n",
    "                    del dataSession['session_names']\n",
    "                    self.dataBehaviourPooled += [dataSession]\n",
    "                    self.dataBehaviourPooledKeys |= set(dataSession.keys())\n",
    "\n",
    "                    # print(dataSession['session_names'])\n",
    "\n",
    "                # print(dataSession.keys())\n",
    "\n",
    "        self.metaDataFrames['pooled_behaviour'] = pooledFrame\n",
    "\n",
    "    # Mark days as naive or expert based on performance threshold\n",
    "    def mark_days_expert_naive(self, pTHR):\n",
    "        nNeuroFiles = self.metaDataFrames['neuro'].shape[0]\n",
    "        self.expertThrIdx = {}  # Which session counting alphabetically is first expert for a given mouse\n",
    "        isExpert = np.zeros(nNeuroFiles, dtype=bool)\n",
    "        deltaDays = np.zeros(nNeuroFiles)\n",
    "        deltaDaysCentered = np.zeros(nNeuroFiles)\n",
    "\n",
    "        # For each mouse, determine which sessions are naive and which expert\n",
    "        # Also determine number of days passed since start and since expert\n",
    "        for mousename in self.mice:\n",
    "            thisMouseMetadata = get_rows_colval(self.metaDataFrames['neuro'], 'mousename', mousename)\n",
    "            thisMouseDataIdxs = np.array(thisMouseMetadata[\"date\"].index)\n",
    "            perf = self.dataPerformance[thisMouseDataIdxs]\n",
    "            skillRez = mouse_performance_allsessions(list(thisMouseMetadata[\"date\"]), perf, pTHR)\n",
    "            self.expertThrIdx[mousename], isExpert[thisMouseDataIdxs], deltaDays[thisMouseDataIdxs], deltaDaysCentered[thisMouseDataIdxs] = skillRez\n",
    "\n",
    "        # Add these values to metadata\n",
    "        self.metaDataFrames['neuro']['isExpert'] = isExpert\n",
    "        self.metaDataFrames['neuro']['deltaDays'] = deltaDays\n",
    "        self.metaDataFrames['neuro']['deltaDaysCentered'] = deltaDaysCentered\n",
    "\n",
    "    def get_channel_labels(self, mousename):\n",
    "        return self.channelLabelsDict[mousename]\n",
    "\n",
    "    def get_nchannels(self, mousename):\n",
    "        return len(self.channelLabelsDict[mousename])\n",
    "\n",
    "    def get_rows(self, frameName, coldict):\n",
    "        return get_rows_colvals(self.metaDataFrames[frameName], coldict)\n",
    "\n",
    "    def get_neuro_data(self, coldict, trialType=None, cropTime=None):\n",
    "        rows = self.get_rows('neuro', coldict)\n",
    "\n",
    "        dataLst = []\n",
    "        for idx, row in rows.iterrows():\n",
    "            # Crop time to have uniform\n",
    "            if cropTime is None:\n",
    "                data = self.dataNeuronal[idx]\n",
    "            else:\n",
    "                data = self.dataNeuronal[idx][:, :cropTime]\n",
    "\n",
    "            # Extract necessary trials or all\n",
    "            if trialType is not None:\n",
    "                assert trialType in ['iGO', 'iNOGO'], \"Unexpected trial type\"\n",
    "                idxsTrials = self.dataTrials[idx][trialType] - 1\n",
    "                data = data[idxsTrials]\n",
    "\n",
    "            dataLst += [data]\n",
    "\n",
    "        return dataLst\n",
    "\n",
    "    # Find FC data for specified rows, then crop to selected time range\n",
    "    def get_fc_data(self, idx, rangeSec=None):\n",
    "        timesThis = self.dataTEtimes[idx]\n",
    "        fcThis = self.dataTEFC[idx]\n",
    "        if rangeSec is None:\n",
    "            return timesThis, fcThis\n",
    "        else:\n",
    "            rng = slice_sorted(timesThis, rangeSec)\n",
    "            return timesThis[rng[0]:rng[1]], fcThis[..., rng[0]:rng[1]]\n",
    "\n",
    "    # Provide rows for all sessions of the same mouse, iterating over combinations of other anaylsis parameters\n",
    "    def mouse_iterator(self):\n",
    "        sweepCols = [\"mousename\",  \"analysis\", \"trial\", \"range\", \"method\"]\n",
    "        sweepValues = [self.summaryTE[colname].keys() for colname in sweepCols]\n",
    "        sweepProduct = list(itertools.product(*sweepValues))\n",
    "\n",
    "        for sweepComb in sweepProduct:\n",
    "            sweepCombDict = dict(zip(sweepCols, sweepComb))\n",
    "            rows = self.get_rows('TE', sweepCombDict)\n",
    "            if rows.shape[0] > 0:\n",
    "                yield sweepCombDict, rows\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36qt5)",
   "language": "python",
   "name": "py36qt5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
