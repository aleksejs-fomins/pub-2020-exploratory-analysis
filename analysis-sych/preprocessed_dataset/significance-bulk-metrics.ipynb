{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from scipy.stats import mannwhitneyu, wilcoxon\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "rootname = \"pub-2020-exploratory-analysis\"\n",
    "thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "from mesostat.utils.qt_helper import gui_fnames, gui_fpath\n",
    "from mesostat.metric.metric import MetricCalculator\n",
    "from mesostat.utils.hdf5_io import DataStorage\n",
    "\n",
    "from lib.sych.data_fc_db_raw import DataFCDatabase\n",
    "import lib.analysis.bulk_metrics as bulk_metrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_path = root_path_data if 'root_path_data' in locals() else \"./\"\n",
    "params = {}\n",
    "# params['root_path_data'] = './'\n",
    "params['root_path_data'] = '/media/alyosha/Data/TE_data/yarodata/sych_preprocessed'\n",
    "#params['root_path_data'] = gui_fpath('h5path', './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB = DataFCDatabase(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataStorage('sych_result_bulk_metrics.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MetricCalculator(serial=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bulk Metrics vs Time\n",
    "\n",
    "* Avg over mice\n",
    "* All-region-all-types\n",
    "* Expert vs Naive\n",
    "* Go/NOGO/MISS/FA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, 'mean', 's', 'time', verbose=False,\n",
    "                               trialTypeNames='auto', perfNames='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'mean', 'time', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance\n",
    "\n",
    "**TODO**\n",
    "* Plot trial variance relative to temporal variance\n",
    "* Plot mean with variance together\n",
    "\n",
    "### Pros/Cons of Baseline Normalization\n",
    "* DFF-Trial\n",
    "    - Pos: Removes dynamic baseline changing on the order of trials.\n",
    "    - Pos: Under assumption of signal-free pre-trial interval, baseline removal enhances relative change in significant activity during trial.\n",
    "    - Neg: In presence of correlation between pre-trial interval and trial signals, this procedure destroys information during trial.\n",
    "\n",
    "* DFF-Session vs ZScore-Session\n",
    "    - Both linear transforms\n",
    "    - Mean is more meaningful for DFF if pre-trial interval is at least somewhat stable\n",
    "    - Va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, 'varmean', 's', 'time', verbose=False,\n",
    "                               trialTypeNames='auto', perfNames='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'varmean', 'time', ylim=[0,None], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variance across channels for interesting interval\n",
    "\n",
    "* Average signal over texture presentation interval\n",
    "* Compute variance over trials for each channel\n",
    "* Compare channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, 'varmean', 'p', 'channel', cropTime=('TEX', (3, 3.5)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'varmean', 'channel', yscale='log', verbose=False, # ylim=[0.005,2],\n",
    "                              dropCols=['cropTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Effective Rank\n",
    "\n",
    "### ByTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"rank_effective\", 's', 'time', verbose=False,\n",
    "                               trialTypeNames='auto', perfNames='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'rank_effective', 'time', ylim=[1, None], verbose=False) # ylim=[1,48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BySession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intervDict = {\n",
    "    'TEX' : (3.0, 3.5),\n",
    "    'REW' : (6.0, 6.5)\n",
    "}\n",
    "\n",
    "for intervName, interv in intervDict.items():\n",
    "    bulk_metrics.metric_mouse_bulk_vs_session(dataDB, mc, ds, \"rank_effective\", 'session',\n",
    "                                              perfNames='auto', verbose=False, cropTime=(intervName, interv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'rank_effective', 'session', ylim=[1,None], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_entropy\", 'sp', 'time-channel', verbose=False)\n",
    "# bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_entropy\", 's', 'time', verbose=False)\n",
    "\n",
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_TC\", 's', 'time', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(dataDB, ds, 'avg_TC', 'time', verbose=True) # ylim=[1,48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_TC(dataDB, ds, ylim=None, yscale=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(ds.list_dsets_pd().sort_values(by='datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.delete_by_query(queryDict={\"metric\" : \"rank_effective\"}, timestr=\"2020-11-20 18:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nest)",
   "language": "python",
   "name": "py36nest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
