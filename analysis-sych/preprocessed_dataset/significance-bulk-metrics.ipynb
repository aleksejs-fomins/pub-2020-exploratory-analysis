{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from scipy.stats import mannwhitneyu, wilcoxon\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "rootname = \"pub-2020-exploratory-analysis\"\n",
    "thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "from mesostat.utils.qt_helper import gui_fnames, gui_fpath\n",
    "from mesostat.metric.metric import MetricCalculator\n",
    "from mesostat.utils.hdf5_io import DataStorage\n",
    "\n",
    "from lib.sych.data_fc_db_raw import DataFCDatabase\n",
    "import lib.analysis.bulk_metrics as bulk_metrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_path = root_path_data if 'root_path_data' in locals() else \"./\"\n",
    "params = {}\n",
    "# params['root_path_data'] = './'\n",
    "params['root_path_data'] = '/media/alyosha/Data/TE_data/yarodata/sych_preprocessed'\n",
    "#params['root_path_data'] = gui_fpath('h5path', './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB = DataFCDatabase(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataStorage('sych_result_bulk_metrics.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MetricCalculator(serial=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervDict = {\n",
    "#     'PRE' : (-2.0, 0.0),\n",
    "#     'TEX' : (3.0, 3.5),\n",
    "#     'REW' : (6.0, 6.5)\n",
    "# }\n",
    "intervDict = {'AVG' : (0.0, 8.0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mean\n",
    "### 1.1. Mean vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, 'mean', 's', 'time', verbose=False, minTrials=10,\n",
    "                               trialTypeNames='auto', perfNames='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'mean', 'time', verbose=False, xFunc=lambda m, l: dataDB.get_times())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Mean vs session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for intervName, interv in intervDict.items():\n",
    "    bulk_metrics.metric_mouse_bulk_vs_session(dataDB, mc, ds, \"mean\", 'session', trialTypeNames='auto',\n",
    "                                              minTrials=10, verbose=False, cropTime=(intervName, interv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.scatter_metric_bulk(ds, 'mean', 'session', verbose=False, xlim=[0, 1],\n",
    "                              xFunc=lambda m, l: dataDB.get_performance_mouse(m), haveRegression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.barplot_conditions(ds, 'mean', 'session', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variance\n",
    "\n",
    "**TODO**\n",
    "* Plot trial variance relative to temporal variance\n",
    "* Plot mean with variance together\n",
    "\n",
    "### Pros/Cons of Baseline Normalization\n",
    "* DFF-Trial\n",
    "    - Pos: Removes dynamic baseline changing on the order of trials.\n",
    "    - Pos: Under assumption of signal-free pre-trial interval, baseline removal enhances relative change in significant activity during trial.\n",
    "    - Neg: In presence of correlation between pre-trial interval and trial signals, this procedure destroys information during trial.\n",
    "\n",
    "* DFF-Session vs ZScore-Session\n",
    "    - Both linear transforms\n",
    "    - Mean is more meaningful for DFF if pre-trial interval is at least somewhat stable\n",
    "    - Va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, 'varmean', 's', 'time', verbose=False, minTrials=50,\n",
    "                               trialTypeNames='auto', perfNames='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'varmean', 'time',\n",
    "                              ylim=[0,None], verbose=False, xFunc=lambda m, l: dataDB.get_times())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for intervName, interv in intervDict.items():\n",
    "    bulk_metrics.metric_mouse_bulk_vs_session(dataDB, mc, ds, \"varmean\", 'session', trialTypeNames='auto',\n",
    "                                              minTrials=50, verbose=False, cropTime=(intervName, interv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.scatter_metric_bulk(ds, 'varmean', 'session', verbose=False,\n",
    "                              xFunc=lambda m, l: dataDB.get_performance_mouse(m), haveRegression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.barplot_conditions(ds, 'varmean', 'session', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variance across channels for interesting interval\n",
    "\n",
    "* Average signal over texture presentation interval\n",
    "* Compute variance over trials for each channel\n",
    "* Compare channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, 'varmean', 'p', 'channel',\n",
    "                               cropTime=('TEX', (3, 3.5)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'varmean', 'channel', yscale='log', verbose=False, # ylim=[0.005,2],\n",
    "                              dropCols=['cropTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Effective Rank\n",
    "\n",
    "### ByTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"rank_effective\", 's', 'time', verbose=False,\n",
    "                               minTrials=50, trialTypeNames='auto', perfNames='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'rank_effective', 'time', ylim=[1, None], verbose=False,\n",
    "                              xFunc=lambda m, l: dataDB.get_times()) # ylim=[1,48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BySession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for intervName, interv in intervDict.items():\n",
    "    bulk_metrics.metric_mouse_bulk_vs_session(dataDB, mc, ds, \"rank_effective\", 'session', minTrials=50,\n",
    "                                              trialTypeNames='auto', verbose=False, cropTime=(intervName, interv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.scatter_metric_bulk(ds, 'rank_effective', 'session', xlim=[0, 1], ylim=[1, None], verbose=False,\n",
    "                                 xFunc=lambda m, l: dataDB.get_performance_mouse(m), haveRegression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.barplot_conditions(ds, 'rank_effective', 'session', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical\n",
    "\n",
    "**TODO**:\n",
    "* Add composite selectors for metric helper\n",
    "   - trialType = iGO & iNOGO\n",
    "   - cropTime = TEX & REW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervDict = {\n",
    "    'PRE' : (-2.0, 0.0),\n",
    "    'TEX' : (3.0, 3.5),\n",
    "    'REW' : (6.0, 6.5)\n",
    "}\n",
    "for intervName, interv in intervDict.items():\n",
    "    bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"rank_effective\", '', 'flat', verbose=False,\n",
    "                                   trialTypeNames='auto',\n",
    "                                   perfNames='auto',\n",
    "                                   cropTime=(intervName, interv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.list_dsets_pd()\n",
    "df = df[df['name'] == 'flat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.round(ds.get_data(dset), 2) for dset in df['dset']]\n",
    "df['rez'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['datetime', 'zscoreDim', 'dset', 'metric', 'name', 'shape', 'target_dim'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesostat.utils.pandas_helper import pd_category_to_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(set(df.columns) - {'mousename', 'rez'})\n",
    "dfMouse = df.pivot(index=index, columns='mousename', values='rez').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfMouse[dfMouse['datatype'] == 'bn_trial']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_entropy\", 'sp', 'time-channel', verbose=False)\n",
    "# bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_entropy\", 's', 'time', verbose=False)\n",
    "\n",
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_TC\", 's', 'time', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(dataDB, ds, 'avg_TC', 'time', verbose=True) # ylim=[1,48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_TC(dataDB, ds, ylim=None, yscale=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(ds.list_dsets_pd().sort_values(by='datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.delete_by_query(queryDict={\"metric\" : \"rank_effective\"}, timestr=\"2020-11-20 18:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
