{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "rootname = \"pub-2020-exploratory-analysis\"\n",
    "thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "from mesostat.utils.qt_helper import gui_fnames, gui_fpath\n",
    "from mesostat.metric.metric import MetricCalculator\n",
    "from mesostat.utils.hdf5_io import DataStorage\n",
    "\n",
    "from lib.sych.data_fc_db_raw import DataFCDatabase\n",
    "import lib.analysis.coactivity as coactivity\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp_path = root_path_data if 'root_path_data' in locals() else \"./\"\n",
    "params = {}\n",
    "# params['root_path_data'] = './'\n",
    "# params['root_path_data'] = '/media/alyosha/Data/TE_data/yarodata/sych_preprocessed'\n",
    "params['root_path_data'] = '/media/aleksejs/DataHDD/work/data/yaro/neuronal-raw-pooled'\n",
    "# params['root_path_data'] = gui_fpath('h5path', './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB = DataFCDatabase(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = DataStorage('sych_result_activity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = MetricCalculator(serial=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataDB.mice)\n",
    "print(dataDB.dataTypes)\n",
    "print(dataDB.trialTypeNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intervDict = {\n",
    "    \"PRE\" : [-2, 0],\n",
    "    \"TEX\" : [3, 3.5],\n",
    "    \"REW\" : [6, 6.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Significance\n",
    "\n",
    "## 1.1. Correlation plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PCA exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Highly uncorrelated channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataLST = dataDB.get_neuro_data({'mousename' : 'mvg_4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesostat.utils.signals.filter import zscore, drop_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRSP = dataLST[-1]\n",
    "dataRP = np.mean(dataRSP[:, 60:70], axis=1)\n",
    "dataRP = drop_PCA(dataRP, 1)\n",
    "CC = np.corrcoef(dataRP.T)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(CC, cmap='jet', vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering, OPTICS\n",
    "\n",
    "# Compute clustering given distance matrix and distance threshold\n",
    "def cluster_dist_matrix(M, t, method='hierarchic'):\n",
    "    if method=='hierarchic':\n",
    "        distTril = np.tril(M, 1)\n",
    "        linkageMatrix = linkage(distTril, method='centroid', metric='euclidean', optimal_ordering=True)\n",
    "        return fcluster(linkageMatrix, t, criterion='maxclust')# - 1  # Original numbering starts at 1 for some reason\n",
    "#         linkageMatrix = linkage(distTril, method='centroid', metric='euclidean')\n",
    "#         rez = fcluster(linkageMatrix, t, criterion='distance')\n",
    "    elif method == 'affinity':\n",
    "        clustering = AffinityPropagation(affinity='precomputed', damping=t).fit(M)\n",
    "        rez =  clustering.labels_\n",
    "    elif method == 'spectral':\n",
    "        clustering = SpectralClustering(affinity='precomputed', assign_labels=\"discretize\", n_init=100).fit(M)\n",
    "        rez =  clustering.labels_\n",
    "    elif method == 'optics':\n",
    "        clustering = OPTICS(metric='precomputed', min_samples=t).fit(M)\n",
    "        rez =  clustering.labels_\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\", method)\n",
    "\n",
    "    # Original numbering may start at something other than 0 for some methods\n",
    "    rez = np.array(rez, dtype=int)\n",
    "    return rez - np.min(rez).astype(int)\n",
    "\n",
    "\n",
    "def cluster_plot(M, clusters):\n",
    "    idxs = np.argsort(clusters)\n",
    "    MSort = CC[idxs][:, idxs]\n",
    "    \n",
    "    idCluster, nCluster = np.unique(clusters, return_counts=True)\n",
    "    nClustCum = np.cumsum(nCluster)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(CC[idxs][:, idxs], cmap='jet', vmin=-1, vmax=1)\n",
    "    \n",
    "    for nLine in nClustCum:\n",
    "        plt.axvline(x=nLine-0.5, linestyle='--', color='black', alpha=0.3)\n",
    "        plt.axhline(y=nLine-0.5, linestyle='--', color='black', alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = cluster_dist_matrix(np.clip(CC, 0, 1), 0.9, method='affinity')\n",
    "print(clusters)\n",
    "cluster_plot(CC, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coactivity.corr_plot_session_composite(dataDB, mc, intervDict, 'corr', 'bn_session',\n",
    "                                             trialTypes=['iGO', 'iNOGO'],\n",
    "                                       performances=['naive', 'expert'],\n",
    "                                       haveMono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop first PCA and explore result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coactivity.corr_plot_session_composite(dataDB, mc, intervDict, 'corr', 'bn_trial',\n",
    "                                             trialTypes={'iGO', 'iNOGO'},\n",
    "                                       performances=['naive', 'expert'],\n",
    "                                       haveMono=False,\n",
    "                                       nDropPCA=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Consistency\n",
    "## 2.1. PCA consistency over mice\n",
    "### 2.1.1. Angle-based consistency\n",
    "\n",
    "Tasks\n",
    "  * Explained variance by phase/session/mouse/trialType\n",
    "     * Do not separate phases, its meaningless. Compute PCA for all timesteps, then see proj differences for phases\n",
    "     * Implement HAC correction\n",
    "\n",
    "  * Global PCA shifts vs session\n",
    "\n",
    "Approaches:\n",
    "  * Eval PCA over all data, select strongest components, plot components as function of cofound\n",
    "  * Eval PCA for cofounds, compare PCA\n",
    "  \n",
    "**Plots**:\n",
    "* Cosine-squared matrix $C^2_{ij} = (R^{1}_{ik}R^{2}_{jk})^2$, where $R^l$ is the PCA-transform\n",
    "* Consistency metric $E = e^1_i e^2_j C^2_{ij}$, where $e^l$ are the eigenvalues\n",
    "\n",
    "**Problem**:\n",
    "The consistency metric $E$ has all necessary ingredients (angles, eigenvalues), but it is not mathematically clear that it behaves the desired way. Solid theory is required for this metric to be useful.\n",
    "\n",
    "**Alternative approach**:\n",
    "Try consistency metric $H(\\frac{C^2_{ij}}{N})$. Should be great at measuring the sparsity of basis coupling. The challenge is to include eigenvalue priority into this metric, since spread of weak eigenvalues is not as relevant as spread of strong ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coactivity.plot_pca_alignment_bymouse(dataDB, datatype='bn_session', trialType=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Eigenvalue-based consistency\n",
    "\n",
    "* Let $x_1$, $x_2$ be some datasets\n",
    "* Let $R_1$, $R_2$ be the corresponding PCA-transforms \n",
    "* Find total variances\n",
    "    - $V_1 = \\sum_i eig_i(x_1) = tr(cov(x_1)) = \\sum_i cov_{ii}(x_1)$\n",
    "    - $V_2 = \\sum_i eig_i(x_2) = tr(cov(x_2)) = \\sum_i cov_{ii}(x_2)$\n",
    "* Find explained variances\n",
    "    - $e_1 = eval(cov(x_1)) = diag(cov(R_1 x_1))$\n",
    "    - $e_2 = eval(cov(x_2)) = diag(cov(R_2 x_2))$\n",
    "* Find explained variances using wrong bases\n",
    "    - $e_{12} = diag(cov(R_2 x_1))$\n",
    "    - $e_{21} = diag(cov(R_1 x_2))$\n",
    "* Find representation errors in explained variance ratios\n",
    "    - $\\epsilon_1 = \\frac{\\sum_i |e^1_i - e^{12}_i|}{2 V_1}$\n",
    "    - $\\epsilon_2 = \\frac{\\sum_i |e^2_i - e^{21}_i|}{2 V_2}$\n",
    "\n",
    "\n",
    "\n",
    "* TODO: iter trialType=[hit, cr, all]\n",
    "* TODO: iter perf=[naive,expert,all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coactivity.plot_pca_consistency(dataDB, intervDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coactivity.plot_pca_consistency(dataDB, intervDict, dropFirst=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. PCA consistency over phases\n",
    "### 2.2.1 Angle-based consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intervDict = {\n",
    "    \"TEX\" : [3, 3.5],\n",
    "    \"REW\" : [6, 6.5]\n",
    "}\n",
    "\n",
    "coactivity.plot_pca_alignment_byphase(dataDB, intervDict, datatype='bn_trial', trialType=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3QT5",
   "language": "python",
   "name": "py3qt5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
