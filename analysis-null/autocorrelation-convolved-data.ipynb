{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mesostat.metric.autocorr import autocorr_d1_3D\n",
    "from mesostat.visualization.mpl_font import update_fonts_axis\n",
    "\n",
    "fontsize = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does AutoCorr(1) depend on number of datapoints\n",
    "\n",
    "**Answer**: Mean is the same, variance decreases. Should be good enough for $N=10^3$ and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDataArr = (10**np.linspace(1, 6, 100)).astype(int)\n",
    "\n",
    "acLst = []\n",
    "for nData in nDataArr:\n",
    "    data = np.random.normal(0,1,(1,1,nData))\n",
    "    acLst += [autocorr_d1_3D(data, {})]\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(nDataArr, acLst)\n",
    "update_fonts_axis(plt.gca(), fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does AC1 depend on convolution timescale\n",
    "\n",
    "**Conclusion**:\n",
    "* AC1 is a monotonic function of convolution timescale\n",
    "* AC1 is a good predictor of the convolution timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.05 # ms, at sampling frequency of 20Hz\n",
    "tauArr = np.linspace(0.1, 1, 50)\n",
    "\n",
    "nT = 1000\n",
    "tArr = np.arange(nT) * dt\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "acMuLst = []\n",
    "acStdLst = []\n",
    "for tau in tauArr:\n",
    "    nKer = int(10 * tau / dt)\n",
    "    kernel = np.exp(-tArr / tau)[:nKer]\n",
    "    ax[0].plot(tArr[:nKer], kernel)\n",
    "    \n",
    "    acLst = []\n",
    "    for iTest in range(200):    \n",
    "        data = np.random.normal(0, 1, nT)\n",
    "        dataConv = np.convolve(data, kernel)[:nT]\n",
    "        acLst += [autocorr_d1_3D(dataConv.reshape((1,1,nT)), {})]\n",
    "        \n",
    "    acMuLst += [np.mean(acLst)]\n",
    "    acStdLst += [np.std(acLst)]\n",
    "\n",
    "acMuLst = np.array(acMuLst)\n",
    "acStdLst = np.array(acStdLst)\n",
    "    \n",
    "ax[1].fill_between(tauArr, acMuLst-acStdLst, acMuLst+acStdLst, alpha=0.2)\n",
    "ax[1].plot(tauArr, acMuLst)\n",
    "\n",
    "ax[0].set_xlabel('time, sec')\n",
    "ax[0].set_title('convolution kernel')\n",
    "ax[1].set_xlabel('convolution timescale, sec')\n",
    "ax[1].set_title('1-step autocorrelation')\n",
    "update_fonts_axis(ax[0], 12)\n",
    "update_fonts_axis(ax[1], 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does AC1 depend on added noise\n",
    "\n",
    "**Concusion**:\n",
    "* AC1 is a monotonic function of the added noise\n",
    "* Given convolution timescale, AC1 is a good predictor of SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10,5))\n",
    "\n",
    "dt = 0.05 # s, at sampling frequency of 20Hz\n",
    "\n",
    "for tau in [0.3, 0.4, 0.5]:  # s, decay timescale\n",
    "\n",
    "    nT = 1000\n",
    "    tArr = np.arange(nT) * dt\n",
    "    noiseFrac = np.linspace(0,1,50)\n",
    "    nKer = int(10 * tau / dt)\n",
    "    kernel = np.exp(-tArr / tau)[:nKer]\n",
    "\n",
    "    ax[0].plot(tArr[:nKer], kernel, label=str(tau))\n",
    "\n",
    "    acMuLst = []\n",
    "    acStdLst = []\n",
    "    for alpha in noiseFrac:    \n",
    "        acLst = []\n",
    "        for iTest in range(100):    \n",
    "            data = np.random.normal(0, 1, nT)\n",
    "            noise = np.random.normal(0, 1, nT)\n",
    "            dataConv = np.convolve(data, kernel)[:nT]\n",
    "            dataNoisy = alpha*noise + (1-alpha)*dataConv\n",
    "\n",
    "            acLst += [autocorr_d1_3D(dataNoisy.reshape((1,1,nT)), {})]\n",
    "\n",
    "        acMuLst += [np.mean(acLst)]\n",
    "        acStdLst += [np.std(acLst)]\n",
    "\n",
    "    acMuLst = np.array(acMuLst)\n",
    "    acStdLst = np.array(acStdLst)\n",
    "\n",
    "    ax[1].fill_between(noiseFrac, acMuLst-acStdLst, acMuLst+acStdLst, alpha=0.2)\n",
    "    ax[1].plot(noiseFrac, acMuLst, label=str(tau))\n",
    "    \n",
    "ax[1].set_ylim([None,1])\n",
    "ax[0].set_xlabel('time, sec')\n",
    "ax[0].set_title('convolution kernel')\n",
    "ax[1].set_xlabel('noise fraction')\n",
    "ax[1].set_title('1-step autocorrelation')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "update_fonts_axis(ax[0], 12)\n",
    "update_fonts_axis(ax[1], 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nest)",
   "language": "python",
   "name": "py36nest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
