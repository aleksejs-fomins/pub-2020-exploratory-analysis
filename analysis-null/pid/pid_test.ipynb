{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Append base directory\n",
    "import os,sys #,inspect\n",
    "rootname = \"pub-2020-exploratory-analysis\"\n",
    "#thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "thispath = os.getcwd()\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "import lib.nullmodels.null3D as null3D\n",
    "import lib.nullmodels.pidtest as pidtest\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Noisy Redundant Scenario\n",
    "\n",
    "We want to check if white noise added to a purely redundant scenario results in correct identification of redundancy\n",
    "\n",
    "$$X = T + \\nu_X$$\n",
    "$$Y = T + \\nu_Y$$\n",
    "$$Z = T + \\nu_Z$$\n",
    "\n",
    "where $Y$ is the target of $X$ and $Z$, and\n",
    "\n",
    "$$T \\sim \\mathcal{N}(0, 1)$$\n",
    "$$\\nu_X, \\nu_Y, \\nu_Z \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "\n",
    "and $\\sigma$ is a free parameter, denoting the Noise-To-Signal ratio. So the signal should be a mixture of redundant signal and white noise.\n",
    "\n",
    "Since the signal is continuous, we bin it using different bin counts.\n",
    "\n",
    "### Noisy Unique Scenario\n",
    "\n",
    "Same as before, but\n",
    "\n",
    "$$X = T + \\nu_X$$\n",
    "$$Y = T + \\nu_Y$$\n",
    "$$Z = \\nu_Z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcDict = {\n",
    "    'red':    null3D.gen_data_red_noisy,\n",
    "    'unq_xz': null3D.gen_data_unq_noisy,\n",
    "    'xor_z':  null3D.gen_data_xor_noisy\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Redundant Scenario - Discrete Case\n",
    "\n",
    "It is important to test if false positives are caused by binning, or are an intrinsic property of the noise in the covariate. Here I propose a discretized noisy redundancy model. Instead of added noise, each variable has a random chance to produce the redundant outcome or a purely random outcome.\n",
    "\n",
    "$$X \\sim A_X \\nu_X + (1 - A_X) T $$\n",
    "$$Y \\sim A_Y \\nu_Y + (1 - A_Y) T $$\n",
    "$$Z \\sim A_Z \\nu_Z + (1 - A_Z) T $$\n",
    "\n",
    "where\n",
    "\n",
    "$$T, \\nu_X, \\nu_Y, \\nu_Z \\sim Ber(0.5) $$\n",
    "$$A_X \\sim Ber(\\alpha_X)$$\n",
    "$$A_Y \\sim Ber(\\alpha_Y)$$\n",
    "$$A_Z \\sim Ber(\\alpha_Z)$$\n",
    "\n",
    "and $\\alpha_X, \\alpha_Y, \\alpha_Z \\in [0, 1]$ are flexible.\n",
    "\n",
    "So, $\\alpha = 0$ means purely redundant signal, and $\\alpha=1$ means purely noisy signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli(n, p):\n",
    "    return (np.random.uniform(0, 1, n) < p).astype(int)\n",
    "\n",
    "def gen_discrete_random(nSample, alphaX=0.5, alphaY=0.5, alphaZ=0.5):\n",
    "    T = bernoulli(nSample, 0.5)\n",
    "    nuX = bernoulli(nSample, 0.5)\n",
    "    nuY = bernoulli(nSample, 0.5)\n",
    "    nuZ = bernoulli(nSample, 0.5)\n",
    "    aX = bernoulli(nSample, alphaX)\n",
    "    aY = bernoulli(nSample, alphaY)\n",
    "    aZ = bernoulli(nSample, alphaZ)\n",
    "    \n",
    "    x = aX*nuX + (1 - aX)*T\n",
    "    y = aY*nuY + (1 - aY)*T\n",
    "    z = aZ*nuZ + (1 - aZ)*T\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing binning-dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompLabels = ['unq_s1', 'unq_s2', 'shd_s1_s2', 'syn_s1_s2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskDict = {\n",
    "    'norand': np.array([0,0,1]),\n",
    "    'randx': np.array([1,0,1]),\n",
    "    'rand': np.array([1,1,1])\n",
    "}\n",
    "\n",
    "for taskName, params in taskDict.items():\n",
    "    print(taskName)\n",
    "    rezDict = {}\n",
    "\n",
    "    # Do continuous tests\n",
    "    for funcName, func in funcDict.items():\n",
    "        for nBins in range(2, 6):        \n",
    "            pid_bin = lambda x, y, z: pidtest.pid_bin(x,y,z, nBins)\n",
    "\n",
    "            gen_data_eff = lambda: func(10000, *params)\n",
    "            rezDF   = pidtest.run_tests(gen_data_eff, pid_bin, decompLabels, nTest=100)\n",
    "            rezDFsh = pidtest.run_tests(gen_data_eff, pid_bin, decompLabels, nTest=100, haveShuffle=True)\n",
    "\n",
    "            rezDict[(funcName, nBins)] = (rezDF, rezDFsh)\n",
    "            \n",
    "    # Do discrete tests\n",
    "    pid_discr = lambda x, y, z: pidtest.pid(np.array([x,y,z]))\n",
    "\n",
    "    gen_data_eff = lambda: gen_discrete_random(10000, *(0.5*params))\n",
    "    rezDF   = pidtest.run_tests(gen_data_eff, pid_discr, decompLabels, nTest=100)\n",
    "    rezDFsh = pidtest.run_tests(gen_data_eff, pid_discr, decompLabels, nTest=100, haveShuffle=True)\n",
    "\n",
    "    rezDict[('red_discr', 2)] = (rezDF, rezDFsh)\n",
    "    \n",
    "    for k, v in rezDict.items():\n",
    "        print(k)\n",
    "        funcName, nBin = k\n",
    "        rezDF, rezDFsh = v\n",
    "\n",
    "        pidtest.plot_test_summary(rezDF, rezDFsh, suptitle=funcName, haveEff=False)\n",
    "        plt.savefig(funcName + '_pid_nbin'+str(nBin)+'_summary_'+taskName+'.png', dpi=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of variance\n",
    "\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_bin = lambda x, y, z: pidtest.pid_bin(x,y,z, 4)\n",
    "pid_discr = lambda x, y, z: pidtest.pid(np.array([x,y,z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do continuous tests\n",
    "for funcName, func in funcDict.items():\n",
    "    print(funcName)\n",
    "    \n",
    "    funcEff = lambda alpha: func(n=1000, sigX=alpha, sigY=alpha, sigZ=alpha)\n",
    "    \n",
    "    pidtest.run_plot_param_effect(funcEff, pid_bin, decompLabels, nTest=200, alphaRange=(0, 2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nSample=10000\n",
    "for funcName, func in funcDict.items():\n",
    "    print(funcName)\n",
    "    \n",
    "    funcEff = lambda alpha: func(n=nSample, sigX=alpha, sigY=alpha, sigZ=alpha)\n",
    "    pidtest.run_plot_param_effect_test(funcEff, pid_bin, decompLabels, nStep=10, nTest=400, alphaRange=(0, 2))\n",
    "    \n",
    "    plt.savefig(funcName + '_pid_nBin4_vareff_n'+str(nSample)+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSample=10000\n",
    "func = lambda alpha: null3D.gen_data_xor_noisy(n=nSample, sigX=alpha, sigY=alpha, sigZ=alpha)\n",
    "pidtest.run_plot_param_effect_test_single(func, pid_bin, decompLabels, 0, nTest=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do discrete tests\n",
    "funcEff = lambda alpha: gen_discrete_random(nSample=1000, alphaX=alpha, alphaY=alpha, alphaZ=alpha)\n",
    "pidtest.run_plot_param_effect(funcEff, pid_discr, decompLabels, nTest=1000, alphaRange=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nSample=10000\n",
    "funcEff = lambda alpha: gen_discrete_random(nSample=nSample, alphaX=alpha, alphaY=alpha, alphaZ=alpha)\n",
    "pidtest.run_plot_param_effect_test(funcEff, pid_discr, decompLabels, nStep=10, nTest=400, alphaRange=(0, 1))\n",
    "\n",
    "plt.savefig('redDiscr_pid_vareff_n'+str(nSample)+'.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of number of samples\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig=1.0\n",
    "for funcName, func in funcDict.items():\n",
    "    print(funcName)\n",
    "\n",
    "    funcEff = lambda n: func(n=n, sigX=sig, sigY=sig, sigZ=sig)\n",
    "    pidtest.run_plot_data_effect_test(funcEff, pid_bin, decompLabels, nStep=10, nTest=400)\n",
    "    \n",
    "    plt.savefig(funcName + '_pid_nBin4_nEff_sig'+str(sig)+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "funcEff = lambda n: gen_discrete_random(nSample=n, alphaX=alpha, alphaY=alpha, alphaZ=alpha)\n",
    "pidtest.run_plot_data_effect_test(funcEff, pid_discr, decompLabels, nStep=10, nTest=400)\n",
    "\n",
    "plt.savefig('redDiscr_pid_nEff_alpha'+str(alpha)+'.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test relationship of synergy and redundancy for fixed data size\n",
    "\n",
    "#### 1. Finding max synergy parameters - GridSearch3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nSample in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nSample)\n",
    "    pidtest.run_gridsearch_3D(null3D.gen_data_red_noisy, pid_bin, 'syn_s1_s2',\n",
    "                              varLimits=(0, 2), nSample=nSample, nStep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nSample in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nSample)\n",
    "    pidtest.run_gridsearch_3D(gen_discrete_random, pid_discr, 'syn_s1_s2',\n",
    "                              varLimits=(0, 1), nSample=nSample, nStep=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Finding max synergy parameters - GridSearch1D\n",
    "\n",
    "Previous analysis found that in all cases maximal synergy is located at the diagonal $\\alpha_x = \\alpha_y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nSample in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nSample)\n",
    "    pidtest.run_plot_1D_scan(null3D.gen_data_red_noisy, pid_bin, 'shd_s1_s2', 'syn_s1_s2',\n",
    "                             varLimits=(0, 2), nSample=nSample, nStep=100, nTest=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nSample in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nSample)\n",
    "    pidtest.run_plot_1D_scan(gen_discrete_random, pid_discr, 'shd_s1_s2', 'syn_s1_s2',\n",
    "                             varLimits=(0, 1), nSample=nSample, nStep=100, nTest=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Determining Synergy-Redundancy Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidtest.run_plot_scatter_explore(null3D.gen_data_red_noisy, pid_bin, 'shd_s1_s2', 'syn_s1_s2', 3,\n",
    "                         varLimits=(0, 0.5), nSample=1000, nTestDim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidtest.run_plot_scatter_explore(gen_discrete_random, pid_discr, 'shd_s1_s2', 'syn_s1_s2', 3,\n",
    "                         varLimits=(0, 1), nSample=1000, nTestDim=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test relationship of unique and redundancy for fixed data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nSample in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nSample)\n",
    "    pidtest.run_plot_1D_scan(null3D.gen_data_red_noisy, pid_bin, 'shd_s1_s2', 'unq_s1',\n",
    "                             varLimits=(0, 1), nSample=nSample, nStep=10, nTest=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
