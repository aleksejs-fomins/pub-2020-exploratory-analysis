{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "rootname = \"pub-2020-exploratory-analysis\"\n",
    "# thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "thispath = os.getcwd()\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "from mesostat.metric.metric import MetricCalculator\n",
    "from mesostat.utils.qt_helper import gui_fname, gui_fnames, gui_fpath\n",
    "from mesostat.utils.hdf5_io import DataStorage\n",
    "from mesostat.utils.pandas_helper import pd_query\n",
    "\n",
    "from lib.gallerosalas.data_fc_db_raw import DataFCDatabase\n",
    "import lib.analysis.triplet_analysis.mousewise as mousewise\n",
    "import lib.analysis.triplet_analysis.calc_reader_mousewise as calc_reader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "# params['root_path_data']  = gui_fpath(\"Path to data collection\",  './')\n",
    "params['root_path_data'] = '/media/alyosha/Data/TE_data/yasirdata_raw/'\n",
    "# params['root_path_data'] = '/home/alyosha/data/yasirdata_raw/'\n",
    "# params['root_path_data'] = '/media/aleksejs/DataHDD/work/data/yasir/yasirdata_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB = DataFCDatabase(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB.calc_shortest_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mice', dataDB.mice)\n",
    "print('nSessions', len(dataDB.sessions))\n",
    "print('datatypes', dataDB.get_data_types())\n",
    "print('nChannel', dataDB.get_nchannels('mou_5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5outname = 'gallerosalas_result_higher_order_df.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mc = MetricCalculator(serial=True, verbose=False, nCore=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataDB.channelAreasDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All - Distribution - Nosession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixPath = '/media/alyosha/Data/TE_data/calculations/pr2/yasir-tex/'\n",
    "\n",
    "pwdH5data = prefixPath + 'pr2_gallerosalas_multimouse_data.h5'\n",
    "pwdH5rand = prefixPath + 'pr2_gallerosalas_multimouse_rand.h5'\n",
    "# pwdH5data = prefixPath + 'pid_gallerosalas_multimouse_nbin_2_data.h5'\n",
    "# pwdH5rand = prefixPath + 'pid_gallerosalas_multimouse_nbin_2_rand.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervNames = dataDB.get_interval_names()\n",
    "#trialTypes = ['Hit', 'CR', 'Miss', 'FA']\n",
    "trialTypes = ['Hit', 'CR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfSummary = calc_reader.summary_df(pwdH5data)\n",
    "dfSummaryDataSizes = calc_reader.summary_update_data_sizes(dfSummary, dataDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfSummaryRand = calc_reader.summary_df(pwdH5rand)\n",
    "dfSummaryRandSizes = calc_reader.summary_update_data_sizes(dfSummaryRand, dataDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Global Significance Testing\n",
    "\n",
    "1. For all sweep get data size\n",
    "2. Inside test, generate AdversaryDist for each data size, save as file\n",
    "3. Load file as dict, provide as argument to test\n",
    "4. In test, produce dataframe: Sweep -> (frac>Shuffle, pValSuffle, frac>Conserv, pValConserv)\n",
    "5. Plot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwdAdversarial = '/media/alyosha/Data/TE_data/pr2_rand_dist.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictAdversarial = calc_reader.read_adversarial_distr_file(pwdAdversarial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezTestShuffle = mousewise.plot_violin_test(pwdH5data, pwdH5rand, dfSummary, dfSummaryRand, thrBig=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rezTestAdversarial = mousewise.plot_violin_test_adversarial(pwdH5data, dictAdversarial, dfSummaryDataSizes, thrBig=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesostat.visualization.mpl_matrix import plot_df_2D_outer_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inf_update(df, key, val):\n",
    "    df.loc[df[key] == np.inf, key] = val\n",
    "    df.loc[df[key] == -np.inf, key] = val\n",
    "    return df\n",
    "\n",
    "rezTestShuffle = inf_update(rezTestShuffle, '-log10(pval)', 1000)\n",
    "rezTestAdversarial = inf_update(rezTestAdversarial, '-log10(pval)', 1000)\n",
    "\n",
    "# Plot significance\n",
    "print('Shuffle-Sign')\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12,4), tight_layout=True)\n",
    "for iPid, pidType in enumerate(['red', 'unique', 'syn']):\n",
    "    dfQuery = pd_query(rezTestShuffle, {'atom': pidType})\n",
    "    plot_df_2D_outer_product(ax[iPid], dfQuery, ['datatype', 'mousename'], ['trialType', 'intervName'],\n",
    "                             '-log10(pval)', vmin=0, vmax=20, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']})\n",
    "    \n",
    "plt.savefig('pr2_tex_neglogpval_shuffle_outer2d.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot significance\n",
    "print('Adv-Sign')\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12,4), tight_layout=True)\n",
    "for iPid, pidType in enumerate(['red', 'unique']):\n",
    "    dfQuery = pd_query(rezTestAdversarial, {'atom': pidType})\n",
    "    plot_df_2D_outer_product(ax[iPid], dfQuery, ['datatype', 'mousename'], ['trialType', 'intervName'],\n",
    "                             '-log10(pval)', vmin=0, vmax=20, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']})\n",
    "    \n",
    "plt.savefig('pr2_tex_neglogpval_adversarial_outer2d.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shuffle-Sign')\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12,4), tight_layout=True)\n",
    "for iPid, pidType in enumerate(['red', 'unique', 'syn']):\n",
    "    dfQuery = pd_query(rezTestShuffle, {'atom': pidType})\n",
    "    plot_df_2D_outer_product(ax[iPid], dfQuery, ['datatype', 'mousename'], ['trialType', 'intervName'],\n",
    "                             'fracSign', vmin=0, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']})\n",
    "    \n",
    "plt.savefig('pr2_tex_significant_shuffle_outer2d.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Adv-Sign')\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12,4), tight_layout=True)\n",
    "for iPid, pidType in enumerate(['red', 'unique']):\n",
    "    dfQuery = pd_query(rezTestAdversarial, {'atom': pidType})\n",
    "    plot_df_2D_outer_product(ax[iPid], dfQuery, ['datatype', 'mousename'], ['trialType', 'intervName'],\n",
    "                             'fracSign', vmin=0, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']})\n",
    "    \n",
    "plt.savefig('pr2_tex_significant_adversarial_outer2d.svg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Shuffle-Big')\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12,4), tight_layout=True)\n",
    "for iPid, pidType in enumerate(['red', 'unique', 'syn']):\n",
    "    dfQuery = pd_query(rezTestShuffle, {'atom': pidType})\n",
    "    plot_df_2D_outer_product(ax[iPid], dfQuery, ['datatype', 'mousename'], ['trialType', 'intervName'],\n",
    "                             'fracBig', vmin=0, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']})\n",
    "    \n",
    "plt.savefig('pr2_tex_big_outer2d.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "testingThresholdsShu = {'unique': {}, 'red': {}, 'syn': {}}\n",
    "\n",
    "with h5py.File(pwdH5rand, 'r') as h5f:\n",
    "    for idx, row in dfSummaryRandSizes.iterrows():\n",
    "        thrU1 = np.quantile(h5f[row['key']][:, 0], 0.99)\n",
    "        thrU2 = np.quantile(h5f[row['key']][:, 0], 0.99)\n",
    "        thrR = np.quantile(h5f[row['key']][:, 0], 0.99)\n",
    "        thrS = np.quantile(h5f[row['key']][:, 0], 0.99)\n",
    "        thrU = (thrU1 + thrU2) / 2\n",
    "        rezDict = {'unique': thrU, 'red': thrR, 'syn': thrS}\n",
    "        \n",
    "        for k, v in rezDict.items():\n",
    "            if row['nData'] in testingThresholdsShu[k].keys():\n",
    "                testingThresholdsShu[k][row['nData']] += [v]\n",
    "            else:\n",
    "                testingThresholdsShu[k][row['nData']] = [v]\n",
    "\n",
    "testingThresholdsShu = {pidType : {k: np.mean(v) for k,v in subDict.items()} for pidType, subDict in testingThresholdsShu.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing thresholds \n",
    "testingThresholdsAdv = {pidType : {k: np.quantile(v, 0.99) for k,v in subDict.items()} for pidType, subDict in dictAdversarial.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingThresholds = {\n",
    "    'unique': testingThresholdsAdv['unique'],\n",
    "    'red': testingThresholdsAdv['red'],\n",
    "    'syn': testingThresholdsShu['syn']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_cdf(pwdH5data, dfSummaryDataSizes, testingThresholds=testingThresholds, printSummary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouse-average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mousewise.barplot_avg(dataDB, pwdH5data, dfSummary, 'intervName', intervNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mousewise.barplot_avg(dataDB, pwdH5data, dfSummary, 'trialType', trialTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_top_singlets(dataDB, pwdH5data, dfSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTop1Dmean = mousewise.plot_top_singlets_bymouse_outer2D(dataDB, pwdH5data, dfSummary, 'syn',\n",
    "                                                          func=np.nanmean, dropna=True, magThr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTop1Dmax = mousewise.plot_top_singlets_bymouse_outer2D(dataDB, pwdH5data, dfSummary, 'syn',\n",
    "                                                          func=np.nanmax, dropna=True, magThr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10), tight_layout=True)\n",
    "\n",
    "for i, datatype in enumerate(['bn_trial', 'bn_session']):\n",
    "    dfQuery = pd_query(dfTop1Dmean, {'datatype': datatype})\n",
    "    dfQuery = dfQuery[dfQuery['trialType'] != 'None']\n",
    "    ax[i].set_title(datatype)\n",
    "    plot_df_2D_outer_product(ax[i], dfQuery, ['label'], ['datatype', 'mousename', 'intervName', 'trialType'],\n",
    "                             'syn', vmin=0, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']}, \n",
    "                             dropEmpty=True)\n",
    "    \n",
    "#plt.savefig('pid_tex_big_outer2d.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10), tight_layout=True)\n",
    "\n",
    "for i, datatype in enumerate(['bn_trial', 'bn_session']):\n",
    "    dfQuery = pd_query(dfTop1Dmax, {'datatype': datatype})\n",
    "    dfQuery = dfQuery[dfQuery['trialType'] != 'None']\n",
    "    ax[i].set_title(datatype)\n",
    "    plot_df_2D_outer_product(ax[i], dfQuery, ['label'], ['datatype', 'mousename', 'intervName', 'trialType'],\n",
    "                             'syn', vmin=0, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']}, \n",
    "                             dropEmpty=True)\n",
    "    \n",
    "# plt.savefig('pid_tex_big_outer2d.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_singlets_brainplot(dataDB, pwdH5data, dfSummary, 'intervName', intervNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_singlets_brainplot(dataDB, pwdH5data, dfSummary, 'trialType',\n",
    "                                  trialTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_singlets_brainplot_mousephase_subpre(dataDB, pwdH5data, dfSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_singlets_brainplot_mousephase_submouse(dataDB, pwdH5data, dfSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_top_triplets(dataDB, pwdH5data, dfSummary, nTop=20)#, dropChannels=['BC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSelectedTriplets = mousewise.plot_filter_top_triplets_bymouse(dataDB, pwdH5data, dfSummary,\n",
    "                                                                nTop=30, thrBig=0.01, nConsistent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10), tight_layout=True)\n",
    "\n",
    "for i, datatype in enumerate(['bn_trial', 'bn_session']):\n",
    "    ax[i].set_title(datatype)\n",
    "    plot_df_2D_outer_product(ax[i], dfSelectedTriplets[datatype], ['label'],\n",
    "                             ['mousename', 'intervName', 'trialType'],\n",
    "                             'syn', vmin=0, vmax=0.1, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']}, \n",
    "                             dropEmpty=True)\n",
    "    \n",
    "plt.savefig('pr2_tex_big_triplets_outer2d.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplet_clusters(fig, ax, dataDB, labelsS1, labelsS2, labelsTrg):\n",
    "    labelsCanon = list(dataDB.map_channel_labels_canon().values())\n",
    "    \n",
    "    clusterDict = {\n",
    "        'source1': [labelsCanon.index(l) for l in labelsS1],\n",
    "        'source2': [labelsCanon.index(l) for l in labelsS2],\n",
    "        'target': [labelsCanon.index(l) for l in labelsTrg],\n",
    "    }\n",
    "    \n",
    "    dataDB.plot_area_clusters(fig, ax, clusterDict, haveLegend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterDictDict = {\n",
    "    'bn_trial': {\n",
    "        'rez1':  [['MOp', 'MOs', 'SSp-ll', 'SSp-tr', 'VISa', 'VISam'],  ['RSPd', 'RSPagl'], ['VISpl', 'VISpor', 'TEa']],\n",
    "        'rez2':  [['AUDd', 'SSs'], ['SSp-n', 'SSp-m', 'SSp-bfd', 'VISal'], ['SSp-ll']],\n",
    "        'rez3':  [['MOp', 'SSp-ul'], ['SSp-ll'], ['VISpm']],\n",
    "        'rez4':  [['SSp-n'], ['RSPd'], ['TEa']]\n",
    "    },\n",
    "    'bn_session': {\n",
    "        'rez1':  [['AUDpo', 'TEa'], ['VISp'], ['SSp-ll']],\n",
    "        'rez2':  [['MOp', 'SSp-tr', 'SSp-ul'], ['SSp-ll', 'VISa'], ['VISpl', 'VISpor', 'VISli']],\n",
    "        'rez3':  [['MOs'], ['RSPd'], ['MOp', 'RSPagl', 'SSp-ll', 'SSp-tr', 'VISa', 'VISam']],\n",
    "        'rez4':  [['MOs'], ['VISam', 'VISpm'], ['RSPd']],\n",
    "        'rez5':  [['SSp-m', 'SSp-n'], ['RSPd'], ['AUDp', 'TEa']],\n",
    "        'rez6':  [['SSp-tr'], ['SSp-ll'], ['SSp-m', 'SSp-n', 'SSs']]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labelsCanon = list(dataDB.map_channel_labels_canon().values())\n",
    "\n",
    "_triplet_to_string = lambda s1,s2,t: str(tuple([s1,s2,t])).replace(\"'\", \"\")\n",
    "\n",
    "for datatype, clusterDict in clusterDictDict.items():\n",
    "    for tripletKey, (s1Lst, s2Lst, trgLst) in clusterDict.items():\n",
    "        print(datatype, s1Lst, s2Lst, trgLst)\n",
    "\n",
    "        dfTot = pd.DataFrame()\n",
    "        groupLst = sorted(list(set(dfSummary.columns) - {'key', 'label', 'syn'}))\n",
    "        for key, dataCond in dfSelectedTriplets[datatype].groupby(groupLst):\n",
    "            dfSub = pd.DataFrame()\n",
    "            for s1 in s1Lst:\n",
    "                for s2 in s2Lst:\n",
    "                    for t in trgLst:\n",
    "                        dfThis = pd_query(dataCond, {'label': _triplet_to_string(s1,s2,t)})\n",
    "                        if len(dfThis) > 0:\n",
    "                            dfSub = dfSub.append(dfThis)\n",
    "\n",
    "    #         print('--', key, len(dfSub))\n",
    "\n",
    "            assert len(dfSub) > 0\n",
    "\n",
    "\n",
    "\n",
    "            rezTmp = np.mean(dfSub['syn'])\n",
    "            dfRow = pd.DataFrame(dict(zip(groupLst, key)), index=[0])\n",
    "            dfRow['syn'] = rezTmp\n",
    "            dfTot = dfTot.append(dfRow)\n",
    "\n",
    "        fig, ax = plt.subplots(ncols=2, figsize=(8,4))\n",
    "        plot_triplet_clusters(fig, ax[0], dataDB, s1Lst, s2Lst, trgLst)\n",
    "        plot_df_2D_outer_product(ax[1], dfTot, ['mousename'],\n",
    "                             ['intervName', 'trialType'],\n",
    "                             'syn', vmin=0, vmax=0.06, orderDict={'intervName': ['PRE', 'TEX', 'DEL', 'REW']}, \n",
    "                             dropEmpty=True)\n",
    "\n",
    "        plt.savefig('large_triplet_brainplot_tex_'+datatype + '_' + tripletKey + '.svg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mousewise.plot_2D_avg(dataDB, pwdH5data, dfSummary, 'intervName', intervNames,\n",
    "                      dropChannels=[16, 26], avgAxis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mousewise.plot_2D_avg(dataDB, pwdH5data, dfSummary, 'trialType', trialTypes,\n",
    "                      dropChannels=[16, 26], avgAxis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trgChName in ['SSp-bfd', 'VISrl', 'AUDp']:\n",
    "    mousewise.plot_2D_target(dataDB, pwdH5data, dfSummary, trgChName,\n",
    "                         'intervName', intervNames, dropChannels=[16, 26])\n",
    "    mousewise.plot_2D_target(dataDB, pwdH5data, dfSummary, trgChName,\n",
    "                         'trialType', trialTypes, dropChannels=[16, 26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for trgChName in ['SSp-bfd', 'VISrl', 'AUDp']:\n",
    "    mousewise.plot_2D_target_mousephase_subpre(dataDB, pwdH5data, dfSummary,\n",
    "                                              trgChName, dropChannels=[16, 26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trgChName in ['SSp-bfd', 'VISrl', 'AUDp']:\n",
    "    mousewise.plot_2D_target_mousephase_submouse(dataDB, pwdH5data, dfSummary,\n",
    "                                                trgChName, dropChannels=[16, 26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pid_joint.plot_2D_bytarget_synergy_cluster(dataDB, pwdAllH5_2, dfSummary, 'BC',\n",
    "                                           dropChannels=None, clusterParam=0.001, dropWeakChannelThr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_joint.plot_unique_top_pairs(dataDB, pwdAllH5_2, dfSummary, nTop=20, dropChannels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pid_joint.plot_consistency_bymouse(pwdAllH5_2, dfSummary, dropChannels=None, kind='fisher', limits=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pid_joint.plot_consistency_byphase(pwdAllH5_2, dfSummary, dropChannels=None,\n",
    "                                   kind='fisher', limits=[0, 1], datatype='bn_trial')\n",
    "pid_joint.plot_consistency_byphase(pwdAllH5_2, dfSummary, dropChannels=None, \n",
    "                                   kind='fisher', limits=[0, 1], datatype='bn_session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pid_joint.plot_consistency_bytrialtype(pwdAllH5_2, dfSummary, dropChannels=None, datatype='bn_trial',\n",
    "                                       trialTypes=['Hit', 'CR'], kind='fisher', fisherThr=0.1, limits=[0, 1])\n",
    "pid_joint.plot_consistency_bytrialtype(pwdAllH5_2, dfSummary, dropChannels=None, datatype='bn_session',\n",
    "                                       trialTypes=['Hit', 'CR'], kind='fisher', fisherThr=0.1, limits=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
