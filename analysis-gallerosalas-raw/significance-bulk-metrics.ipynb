{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from scipy.stats import mannwhitneyu, wilcoxon\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "rootname = \"pub-2020-exploratory-analysis\"\n",
    "thispath = os.getcwd()\n",
    "# thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "from mesostat.utils.qt_helper import gui_fnames, gui_fpath\n",
    "from mesostat.metric.metric import MetricCalculator\n",
    "from mesostat.utils.hdf5_io import DataStorage\n",
    "\n",
    "from lib.gallerosalas.data_fc_db_raw import DataFCDatabase\n",
    "from lib.common.metric_helper import calc_metric_mouse, calc_metric_session, calc_metric_mouse_delay\n",
    "import lib.analysis.bulk_metrics as bulk_metrics\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "# params['root_path_data']  = gui_fpath(\"Path to data collection\",  './')\n",
    "params['root_path_data'] = '/media/alyosha/Data/TE_data/yasirdata_raw/'\n",
    "# params['root_path_data'] = '/home/alyosha/data/yasirdata_raw/'\n",
    "# params['root_path_data'] = '/media/aleksejs/DataHDD/work/data/yasir/yasirdata_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB = DataFCDatabase(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataStorage('gallerosalas_bulk_metrics.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MetricCalculator(serial=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mice', dataDB.mice)\n",
    "print('nSessions', len(dataDB.sessions))\n",
    "print('datatypes', dataDB.get_data_types())\n",
    "print('nChannel', dataDB.get_nchannels('mou_5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB.calc_shortest_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argSweepDictTime = {\n",
    "    'trialType': 'auto',\n",
    "    'datatype': ['bn_trial', 'bn_session']\n",
    "}\n",
    "\n",
    "argSweepDictSession = {\n",
    "    'trialType': 'auto',\n",
    "    'intervName': [\"PRE\", \"TEX\", \"DEL\", \"REW\", \"AVG\"],\n",
    "    'datatype': ['bn_trial', 'bn_session']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclQueryLst = [\n",
    "    {'datatype' : 'bn_trial', 'intervName' : 'PRE'},  # Baseline normalized\n",
    "    {'mousename' : 'mou_6', 'intervName' : 'REW'},    # No reward for this mouse\n",
    "    {'mousename' : 'mou_6', 'intervName' : 'AVG'},    # Makes no sense to compare: no reward and longer delay\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mean\n",
    "### 1.1. Mean vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metric_mouse_delay(dataDB, mc, ds, 'mean', 's', 'time', verbose=False, minTrials=10, haveDelay=True,\n",
    "                        skipExisting=False, exclQueryLst=exclQueryLst, **argSweepDictTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bulk_metrics.plot_metric_bulk(ds, 'mean', 'time', verbose=False, xFunc=lambda m, l: dataDB.get_times())\n",
    "bulk_metrics.plot_metric_bulk_1D(dataDB, ds, 'mean', 'time', verbose=False, haveTimeLabels=False,\n",
    "                                 xFunc=lambda m, l: dataDB.get_times())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Mean vs session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metric_session(dataDB, mc, ds, 'mean', '', 'session', verbose=False, minTrials=10,\n",
    "                    skipExisting=False, exclQueryLst=exclQueryLst, **argSweepDictSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.scatter_metric_bulk(ds, 'mean', 'session', verbose=False, xFunc=None, haveRegression=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.barplot_conditions(ds, 'mean', 'session', verbose=True,\n",
    "                                trialTypes=['Hit', 'CR'],\n",
    "                                intervNames=dataDB.get_interval_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variance\n",
    "\n",
    "**TODO**\n",
    "* Plot trial variance relative to temporal variance\n",
    "* Plot mean with variance together\n",
    "\n",
    "### Pros/Cons of Baseline Normalization\n",
    "* DFF-Trial\n",
    "    - Pos: Removes dynamic baseline changing on the order of trials.\n",
    "    - Pos: Under assumption of signal-free pre-trial interval, baseline removal enhances relative change in significant activity during trial.\n",
    "    - Neg: In presence of correlation between pre-trial interval and trial signals, this procedure destroys information during trial.\n",
    "\n",
    "* DFF-Session vs ZScore-Session\n",
    "    - Both linear transforms\n",
    "    - Mean is more meaningful for DFF if pre-trial interval is at least somewhat stable\n",
    "    - Va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metric_mouse_delay(dataDB, mc, ds, 'varmean', 's', 'time', verbose=False, minTrials=30, haveDelay=True,\n",
    "                  skipExisting=False, exclQueryLst=exclQueryLst, **argSweepDictTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk_1D(dataDB, ds, 'varmean', 'time', verbose=False, haveTimeLabels=True,\n",
    "                                 ylim=[0,None], xFunc=lambda m, l: dataDB.get_times())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metric_session(dataDB, mc, ds, 'varmean', '', 'session', verbose=False, minTrials=30,\n",
    "                    skipExisting=False, exclQueryLst=exclQueryLst, **argSweepDictSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.scatter_metric_bulk(ds, 'varmean', 'session', verbose=False, xFunc=None, haveRegression=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.barplot_conditions(ds, 'varmean', 'session',\n",
    "                                verbose=True,\n",
    "                                trialTypes=['Hit', 'CR'],\n",
    "                                intervNames=['PRE', 'DEL', 'TEX', 'REW'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variance across channels for interesting interval\n",
    "\n",
    "* Average signal over texture presentation interval\n",
    "* Compute variance over trials for each channel\n",
    "* Compare channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_metric_mouse(dataDB, mc, ds, 'varmean', 'p', 'channel', verbose=False, minTrials=30,\n",
    "                  skipExisting=False, exclQueryLst=exclQueryLst, **argSweepDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(ds, 'varmean', 'channel', yscale='log', verbose=False) # ylim=[0.005,2], dropCols=['cropTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Effective Rank\n",
    "\n",
    "### ByTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metric_mouse_delay(dataDB, mc, ds, 'rank_effective', 's', 'time', verbose=False, minTrials=50,\n",
    "                        metricSettings={'allowBadData': True}, haveDelay=True, skipExisting=False,\n",
    "                        exclQueryLst=exclQueryLst, **argSweepDictTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk_1D(dataDB, ds, 'rank_effective', 'time', verbose=False, haveTimeLabels=True,\n",
    "                                 ylim=[1,None], xFunc=lambda m, l: dataDB.get_times())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BySession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calc_metric_session(dataDB, mc, ds, 'rank_effective', '', 'session',\n",
    "                    verbose=False, minTrials=30,\n",
    "                    skipExisting=False,\n",
    "                    exclQueryLst=exclQueryLst,\n",
    "                    **argSweepDictSession)  # trialTypeNames=[None, 'Hit', 'CR'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.scatter_metric_bulk(ds, 'rank_effective', 'session', ylim=[1, None], verbose=False,\n",
    "                                 xFunc=None, haveRegression=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_metrics.barplot_conditions(ds, 'rank_effective', 'session',\n",
    "                                verbose=True, trialTypes=['Hit', 'CR'],\n",
    "                                intervNames=dataDB.get_interval_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_entropy\", 'sp', 'time-channel', verbose=False)\n",
    "# bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_entropy\", 's', 'time', verbose=False)\n",
    "\n",
    "bulk_metrics.metric_mouse_bulk(dataDB, mc, ds, \"avg_TC\", 's', 'time', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_metric_bulk(dataDB, ds, 'avg_TC', 'time', verbose=True) # ylim=[1,48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bulk_metrics.plot_TC(dataDB, ds, ylim=None, yscale=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(ds.list_dsets_pd().sort_values(by='datetime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.delete_by_query(queryDict={\"metric\" : \"rank_effective\"}, timestr=\"2020-11-20 18:00:00\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
